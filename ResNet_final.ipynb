{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heayounchoi/ResNet-CIFAR10/blob/main/ResNet_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RylIOxPO6rtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "checkpoints = '/content/drive/MyDrive/Colab Notebooks/ResNet/checkpoints/'\n",
        "if not os.path.exists(checkpoints):\n",
        "    os.makedirs(checkpoints)"
      ],
      "metadata": {
        "id": "grsDXzZP6vqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "7ChyzRBK676u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "sweep_config = {\n",
        "    \"method\": \"grid\",\n",
        "    \"metric\": {\"goal\": \"minimize\", \"name\": \"loss\"},\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [100]},\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "DeFlqBB08tH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, 4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"/content/drive/MyDrive/Colab Notebooks/ResNet/dataset/\",\n",
        "                                 train=True,\n",
        "                                 download=True,\n",
        "                                 transform=transform)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=\"/content/drive/MyDrive/Colab Notebooks/ResNet/dataset/\",\n",
        "                                train=False,\n",
        "                                download=True,\n",
        "                                transform=transform_test)\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "validation_size = len(train_dataset) - train_size\n",
        "\n",
        "train_dataset, validation_dataset = random_split(train_dataset, [train_size, validation_size])"
      ],
      "metadata": {
        "id": "SfCf1T-y7G-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "validation_loader = DataLoader(dataset=validation_dataset,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "h73y58Wu7btk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_size = 0\n",
        "for (X_train, Y_train) in train_loader:\n",
        "    X_train_size = X_train.size()[1:]\n",
        "    print(X_train_size)\n",
        "    print(f\"X_train: {X_train.size()} type: {X_train.type()}\")\n",
        "    print(f\"Y_train: {Y_train.size()} type: {Y_train.type()}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE1wMEq77dSa",
        "outputId": "b49af4d9-81b3-40fb-ae77-9598dc425396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "X_train: torch.Size([128, 3, 32, 32]) type: torch.FloatTensor\n",
            "Y_train: torch.Size([128]) type: torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"사용하는 Device :\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f88oToAR7ve6",
        "outputId": "ca96fa9d-e3c8-470c-94d7-ee9b2037674d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용하는 Device : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(planes),\n",
        "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(planes)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "min_features = 64\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = min_features\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, min_features, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(min_features),\n",
        "            nn.ReLU(),\n",
        "            self._make_layer(block, min_features, num_blocks, stride=1),\n",
        "            self._make_layer(block, min_features*2, num_blocks, stride=2),\n",
        "            self._make_layer(block, min_features*4, num_blocks, stride=2),\n",
        "            self._make_layer(block, min_features*8, num_blocks, stride=2),\n",
        "        )\n",
        "        self.linear = nn.Linear(min_features*8, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu' )\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, std=1e-3)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def resnet20():\n",
        "    return ResNet(BasicBlock, 3)\n",
        "\n",
        "def resnet32():\n",
        "    return ResNet(BasicBlock, 5)\n",
        "\n",
        "def resnet44():\n",
        "    return ResNet(BasicBlock, 7)\n",
        "\n",
        "def resnet56():\n",
        "    return ResNet(BasicBlock, 9)\n",
        "\n",
        "def resnet110():\n",
        "    return ResNet(BasicBlock, 18)\n",
        "\n",
        "def resnet1202():\n",
        "    return ResNet(BasicBlock, 200)"
      ],
      "metadata": {
        "id": "7rf3FEGL8lnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet20().to(DEVICE)\n",
        "summary(model, (1, *X_train_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mez1FQmb8CKS",
        "outputId": "6447283b-af32-4138-c394-fa5d88e03739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "ResNet                                        [1, 10]                   --\n",
              "├─Sequential: 1-1                             [1, 512, 4, 4]            --\n",
              "│    └─Conv2d: 2-1                            [1, 64, 32, 32]           1,728\n",
              "│    └─BatchNorm2d: 2-2                       [1, 64, 32, 32]           128\n",
              "│    └─ReLU: 2-3                              [1, 64, 32, 32]           --\n",
              "│    └─Sequential: 2-4                        [1, 64, 32, 32]           --\n",
              "│    │    └─BasicBlock: 3-1                   [1, 64, 32, 32]           73,984\n",
              "│    │    └─BasicBlock: 3-2                   [1, 64, 32, 32]           73,984\n",
              "│    │    └─BasicBlock: 3-3                   [1, 64, 32, 32]           73,984\n",
              "│    └─Sequential: 2-5                        [1, 128, 16, 16]          --\n",
              "│    │    └─BasicBlock: 3-4                   [1, 128, 16, 16]          230,144\n",
              "│    │    └─BasicBlock: 3-5                   [1, 128, 16, 16]          295,424\n",
              "│    │    └─BasicBlock: 3-6                   [1, 128, 16, 16]          295,424\n",
              "│    └─Sequential: 2-6                        [1, 256, 8, 8]            --\n",
              "│    │    └─BasicBlock: 3-7                   [1, 256, 8, 8]            919,040\n",
              "│    │    └─BasicBlock: 3-8                   [1, 256, 8, 8]            1,180,672\n",
              "│    │    └─BasicBlock: 3-9                   [1, 256, 8, 8]            1,180,672\n",
              "│    └─Sequential: 2-7                        [1, 512, 4, 4]            --\n",
              "│    │    └─BasicBlock: 3-10                  [1, 512, 4, 4]            3,673,088\n",
              "│    │    └─BasicBlock: 3-11                  [1, 512, 4, 4]            4,720,640\n",
              "│    │    └─BasicBlock: 3-12                  [1, 512, 4, 4]            4,720,640\n",
              "├─Linear: 1-2                                 [1, 10]                   5,130\n",
              "===============================================================================================\n",
              "Total params: 17,444,682\n",
              "Trainable params: 17,444,682\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 857.43\n",
              "===============================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 13.76\n",
              "Params size (MB): 69.78\n",
              "Estimated Total Size (MB): 83.55\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "def train(config):\n",
        "  criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "  total_epochs = config.epochs\n",
        "\n",
        "  try:\n",
        "      checkpoint = torch.load(checkpoints + 'ResNet_final/last_epoch')\n",
        "      old_model_state_dict = checkpoint['model_state_dict']\n",
        "      new_model_state_dict = model.state_dict()\n",
        "\n",
        "      for name, param in old_model_state_dict.items():\n",
        "          if name in new_model_state_dict:\n",
        "              try:\n",
        "                  new_model_state_dict[name].copy_(param)\n",
        "              except Exception as e:\n",
        "                  print(f\"Failed to copy param: {name}, due to {e}\")\n",
        "\n",
        "      model.load_state_dict(new_model_state_dict, strict=False)\n",
        "\n",
        "      last_epoch = checkpoint['epoch']\n",
        "      train_losses = checkpoint[\"train_losses\"]\n",
        "      val_losses = checkpoint[\"val_losses\"]\n",
        "      best_val_loss = checkpoint[\"best_val_loss\"]\n",
        "\n",
        "  except:\n",
        "      checkpoint = None\n",
        "      last_epoch = -1\n",
        "      best_val_loss = float('inf')\n",
        "      train_losses = []\n",
        "      val_losses = []\n",
        "\n",
        "  finally:\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_epochs)\n",
        "      if checkpoint:\n",
        "          optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "          scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
        "\n",
        "      for epoch in tqdm(range(last_epoch + 1, total_epochs), desc='Epoch Progress'):\n",
        "          avg_cost = 0\n",
        "\n",
        "          model.train()\n",
        "          train_loss = 0.0\n",
        "          correct_train = 0\n",
        "          total_train = 0\n",
        "\n",
        "          with tqdm(total=len(train_loader), desc='Batch Progress') as batch_bar:\n",
        "              for X, Y in train_loader:\n",
        "                  X = X.to(DEVICE)\n",
        "                  Y = Y.to(DEVICE)\n",
        "\n",
        "                  optimizer.zero_grad()\n",
        "                  hypothesis = model(X)\n",
        "                  loss = criterion(hypothesis, Y)\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "                  train_loss += loss.item()\n",
        "\n",
        "                  _, predicted_train = torch.max(hypothesis.data, 1)\n",
        "                  total_train += Y.size(0)\n",
        "                  correct_train += (predicted_train == Y).sum().item()\n",
        "\n",
        "                  batch_bar.update()\n",
        "\n",
        "              train_losses.append(train_loss / len(train_loader))\n",
        "              train_accuracy = (100 * correct_train) / total_train\n",
        "\n",
        "              model.eval()\n",
        "              val_loss = 0.0\n",
        "\n",
        "              with torch.no_grad():\n",
        "                  correct = 0\n",
        "                  total = 0\n",
        "                  for X, Y in validation_loader:\n",
        "                      X = X.to(DEVICE)\n",
        "                      Y = Y.to(DEVICE)\n",
        "\n",
        "                      output = model(X)\n",
        "                      _, predicted = torch.max(output, 1)\n",
        "\n",
        "                      val_loss += criterion(output, Y).item()\n",
        "\n",
        "                      total += Y.size(0)\n",
        "                      correct += (predicted == Y).sum().item()\n",
        "\n",
        "                  val_losses.append(val_loss / len(validation_loader))\n",
        "                  val_accuracy = correct / total\n",
        "                  scheduler.step()\n",
        "\n",
        "              train_desc = {\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'scheduler_state_dict': scheduler.state_dict(),\n",
        "              'train_accuracy': train_accuracy,\n",
        "              'val_accuracy': val_accuracy * 100,\n",
        "              'train_losses': train_losses,\n",
        "              'val_losses': val_losses,\n",
        "              'best_val_loss': best_val_loss\n",
        "              }\n",
        "\n",
        "              if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save(train_desc, checkpoints + f'ResNet_final/best_epoch')\n",
        "\n",
        "              torch.save(train_desc, checkpoints+f'ResNet_final/last_epoch')\n",
        "\n",
        "              wandb.log({\"train_accuracy\": train_accuracy, \"val_accuracy\": val_accuracy*100,\n",
        "                          \"train_losses\": train_losses[-1], \"val_losses\": val_losses[-1]}, step=epoch)\n",
        "\n",
        "              print('Epoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.4f}%, Val Loss: {:.4f}, Val Accuracy: {:.2f}%'\n",
        "                      .format(epoch, total_epochs, train_losses[-1], train_accuracy, val_losses[-1], val_accuracy*100))\n",
        "\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for X, Y in test_loader:\n",
        "          X = X.to(DEVICE)\n",
        "          Y = Y.to(DEVICE)\n",
        "\n",
        "          output = model(X)\n",
        "          loss = criterion(output, Y)\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(output, 1)\n",
        "          total += Y.size(0)\n",
        "          correct += (predicted == Y).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader)\n",
        "  test_accuracy = correct / total\n",
        "\n",
        "  wandb.log({\"test_loss\": test_loss, \"test_accuracy\": test_accuracy*100})\n",
        "  wandb.alert(\"[ResNet_final]Training Task Finished\", f\"test_accuracy: {str(test_accuracy*100)}\")\n",
        "  return val_losses[-1]"
      ],
      "metadata": {
        "id": "4BAe0AT1NuKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}